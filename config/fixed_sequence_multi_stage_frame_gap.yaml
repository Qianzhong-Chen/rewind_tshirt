_target_: workspace.fixed_sequence_multi_stage_frame_gap_ws.RewindRewardWorkspace

cfg:
  general:
    # dataset specific
    project_name: "rewind_reward_fixed_seq_model_frame_gap_multi_stage"
    task_name: "fold_tshirt"
   
    repo_id: Qianzhong-Chen/tshirt_reward_anno_0717 # two-staged dataset, 1epoch 15k steps
    # repo_id: Qianzhong-Chen/tshirt_reward_test_0717
    # repo_id: Qianzhong-Chen/tshirt_reward_debug
    state_norm_path: "/home/david_chen/rewind_tshirt/assets/fold_tshirt.json"
    camera_names:  [top_camera-images-rgb]
    seed: 42
    device: "cuda"        # "cpu" for debugging

  dataloader:
    batch_size: 48
    num_workers: 16 # nproc=32
    shuffle: True
    pin_memory: True
    persistent_workers: True

  val_dataloader:
    batch_size: 48
    num_workers: 16
    shuffle: False
    pin_memory: True
    persistent_workers: True

  rollout_dataloader:
    batch_size: 1 # don't change
    num_workers: 20
    shuffle: True
    pin_memory: True
    persistent_workers: True

  encoders:               
    # # DINO
    # vision_ckpt: "facebook/dinov2-base"
    # text_ckpt:   "sentence-transformers/all-MiniLM-L6-v2"
    # # text_ckpt:   "sentence-transformers/paraphrase-MiniLM-L3-v2"

    # CLIP
    vision_ckpt: "openai/clip-vit-base-patch32"
    text_ckpt: "openai/clip-vit-base-patch32"

  model:
    d_model: 512          # CLS width of dinov2-base
    max_seq_len: 128
    n_layers: 4
    n_heads: 8
    dropout: 0.1
    horizon: 6
    n_obs_steps: 6
    max_rewind_steps: 4
    frame_gap: 15
    state_dim: 14
    no_state: True
    num_classes: 6 # num_classes = num_stage + 1
    dense_annotation: False # check the rule inside the dataset class to allign with progress
    annotation_list: ["Grab the tshirt from the pile", 
                      "Move the tshirt to the center of the board",
                      "Flatten the tshirt out",
                      "Fold the tshirt",
                      "Neatly place the folded tshirt to the corner",
                      "task finished"]

  optim:
    lr: 5e-5
    weight_decay: 1.0e-3
    betas: [0.9, 0.95]
    eps: 1.0e-8
    warmup_steps: 500
    total_steps: 30_000

  train:
    num_epochs: 4
    grad_clip: 1.0
    log_every: 50        # steps
    eval_every: 1        # epochs
    save_every: 5000     # steps
    val_portion: 0.1     # fraction of episodes for validation
    rollout_every: 1     # epoch
    rollout_steps: 10    # steps per rollout

  eval:
    run_times: 50        # number of rollouts
    video_run_times: 50 # number of episodes to evaluate in video
    # ckpt_path: "/home/david_chen/rewind_tshirt/outputs/2025-07-19/00-52-24/rewind_reward_fixed_seq_model_frame_gap_multi_stage/fold_tshirt/checkpoints" # non_dense anno, frame_gap=50
    # ckpt_path: "/home/david_chen/rewind_tshirt/outputs/2025-07-21/13-00-24/rewind_reward_fixed_seq_model_frame_gap_multi_stage/fold_tshirt/checkpoints" # non_dense anno, frame_gap=15
    ckpt_path: "/home/david_chen/rewind_tshirt/outputs/2025-07-26/07-30-57/rewind_reward_fixed_seq_model_frame_gap_multi_stage/fold_tshirt/checkpoints" # non_dense anno, non_joint, top_cam_only frame_gap=15
    raw_data_path: "/nfs_old/david_chen/dataset/tshirt_yam_200_0718/folding_tshirt/episode_z_zFIjhMduwurhFLtp01MJYJv25UttTH9ocB7q9xQic.npy.mp4"
    raw_data_dir: "/nfs_old/david_chen/dataset/tshirt_yam_200_0718/folding_tshirt"
    # raw_data_dir: /nfs_old/david_chen/dataset/tshirt_reward_test
    # raw_data_dir: /nfs_old/david_chen/dataset/tshirt_reward_debug
    raw_data_run_times: 50
